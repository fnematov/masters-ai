Interesting thing here is it's also possible to use machine learning techniques and all this concept of token we've been discussing previously in working with speech and understanding the speech. And the project I would like to show you, this Whisper. So let me find, it should be here in the notes I put. Yeah, this one. It was introduced very similar once the ChatGPT arrived, right? So I'm just trying to recognize what was the time when ChatGPT released. OK, when ChatGPT released. OK, November 30. All right, 2022. Yeah, so they introduced Whisper a couple of months before ChatGPT. And do you know what happens? Do you remember this movie, 13th Floor? This one. So do you know this movie, 13th Floor? It's kind of popular from a scientific perspective, but they got the problem, right? So this is the cyber, like not so cyberpunk, but probably like interesting science fiction. But take a look at the release year. It's 1999. The problem is that in 1999, this movie gets out, Matrix. And that's why like everyone known about the Matrix, it was like very successful movie. And this is the reason much more less people know that this movie, 13th Floor, even exists. If they release it like a year previous, before Matrix, so much more success. So the same as Whisper, right? So ChatGPT released November 13, and Whisper, actually the same company, OpenAI, but it was not so hyped in September as it become in November, right? So what they introduced is they actually been working like at the same time, looks like they've been working at the Whisper in parallel, like working with ChatGPT, right? So they reused the same, like not the same, but similar architecture, like encoders, decoders, and tokens to predict the tokens, but not from text, but from audio as well. So they just take a look at the audio, right? And in the paper, so they share like this one. So they took 680,000 hours of multilingual audio. So they sliced it in 30 seconds, like steps, not steps, but chunks. And they trained the model against it using the same approach they used for the GPT. So pretty the same, like slice the data into some samples, try to predict the tokens, like compare with the result, learn, train the model, and so on. And this results in a very interesting thing. Very high quality. And I don't know if there are any model right now which can beat the quality of Whisper. Because once it was released, it was like very high quality. They released another model a couple of months ago. I think it's called Whisper Turbo. But the architecture seems to stay the same. And one more interesting thing here is it's completely open sourced. So you can download it. And it doesn't require a lot of VRAM to run. So you can run it on the GPU. You can run it a bit slower on the CPU. And as far as it's not a large language model, it will perform with acceptable speed. I've been running it at the CPU once. And it works normally, so not so slow as the LLM. We are not so interested in technical details. And I don't understand them, actually, just to explain to you. But what we're interested in is actually we're interested in the result. So how it works and how I can use it. So how to use it. So you just install it as a Python package. But you need PyTorch. And this is why I mentioned the PyTorch previously. So in order to install it locally, so you must have the PyTorch. And this is the command. It should be PyTorch download.